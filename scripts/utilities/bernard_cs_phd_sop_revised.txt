Statement of Purpose
Bernard Boateng

How can we bridge the gap between cutting-edge AI capabilities and the urgent needs of domain experts? While large language models have revolutionized information access, a critical disconnect remains: practitioners in resource-constrained settings still struggle with manual analysis while AI systems capable of complex reasoning remain inaccessible. This paradox drives my research interest at the intersection of NLP and real-world applications, where I aim to explore how AI can become more accessible and useful for non-technical users.

Through developing ChatMRPT—a conversational AI system that enables Nigerian health officials to analyze malaria risk through natural language—I discovered both the transformative potential and current limitations of applying LLMs to public health challenges. This experience, combined with my review of current literature, revealed several fundamental research questions I am interested in exploring.

First, how can we adapt language models to understand domain-specific terminology and reasoning patterns? While specialized models like BioBERT excel at processing formal literature, they fail to capture operational language—the difference between textbook terminology and field practice. Through ChatMRPT, I discovered that current LLMs struggle with contextual reasoning: they cannot determine appropriate aggregation levels without explicit instruction. I'm interested in exploring retrieval-augmented generation (RAG) and few-shot learning techniques to help models adapt to specialized domains, particularly investigating how chain-of-thought prompting could enable models to ask clarifying questions and recognize missing information like human experts do.

Second, how can we design AI systems that coordinate multiple analytical approaches for complex tasks? Building ChatMRPT showed me that real-world problems require orchestrating different types of reasoning—numerical, spatial, and textual—simultaneously. I'm interested in exploring multi-agent architectures where specialized models collaborate through structured communication protocols. Specifically, I want to investigate how techniques like neural module networks and compositional reasoning could enable dynamic tool selection and coordination while maintaining interpretability for end users.

Third, how do we ensure AI systems remain robust and fair across diverse deployment contexts? Models trained on data from well-resourced settings often fail in resource-constrained environments. I'm interested in exploring domain adaptation techniques and distributionally robust optimization to address these disparities. Additionally, I want to investigate participatory design methods that involve end users in defining evaluation metrics relevant to their specific contexts.

My path to computer science began during my civil engineering studies at the University of Johannesburg, where I discovered the power of programming to automate complex calculations. For my final year project, I developed a machine learning system for structural load-bearing analysis that integrated sensor data with predictive models, demonstrating 25% improvement in failure prediction accuracy compared to traditional methods. This project, which earned recognition from faculty, inspired me to pursue graduate studies in data science.

During my Master's in Data Science at Loyola University Chicago (GPA: 3.73), I began exploring how computational methods could address challenges I'd observed in global health. Natural Language Processing (COMP 429) opened my eyes to the potential of transformer models and conversational AI, though I didn't yet know I'd apply these concepts to support health officials in Nigeria. Big Data Analytics (COMP 458) with Dr. Mohammed Abuhamad challenged me to think beyond single-machine solutions—a perspective that proved essential when I later needed to process large geospatial data efficiently. The statistical foundations from Predictive Analytics (STAT 438) gave me tools to handle the messy, incomplete data that characterizes real-world health applications.

As lead developer of ChatMRPT at Loyola's Urban Malaria Lab, I addressed a critical challenge: health officials in Nigeria lacked the statistical expertise and technical capacity to analyze complex datasets for malaria intervention planning, often outsourcing analysis at significant cost and delay. I built a conversational AI system through three key innovations. First, I created a multi-modal pipeline integrating demographic CSVs and shapefiles through natural language commands, using GeoPandas for spatial operations and custom NLP parsing for query interpretation. While the system processes satellite-derived risk indicators, these are pre-computed environmental factors rather than raw imagery. Second, I implemented a context-aware request interpreter using a hierarchical state machine that maintains conversation history across analytical steps, enabling users to build complex queries iteratively. Third, I architected a scalable deployment on AWS using distributed caching and lazy loading strategies, reducing query response time from minutes to under 2 seconds for 15GB datasets. The system is now primed to serve health officials across multiple Nigerian states.

During my internship, I developed a Factorization-based Texture Segmentation model for classifying urban settlements from satellite imagery. Working with 10,000+ images, I implemented a feature extraction pipeline combining spectral and textural features that identified previously unrecognized informal settlements. This experience with multi-modal data processing directly informed my later work on ChatMRPT's architecture.

Loyola offers an exceptional interdisciplinary environment for my research through established collaborations with my co-supervisors. Dr. Ifeoma Ozodiegwu, who leads the Urban Malaria Lab in the Health Informatics and Data Science Department, brings deep expertise in mathematical modeling for malaria intervention planning and urban malaria microstratification. Her work developing frameworks for sub-national intervention tailoring directly complements the technical capabilities of ChatMRPT. Through our collaboration, we've identified how AI can address critical gaps in epidemiological analysis—her field experience ensures our research solutions address real constraints faced by health programs. Dr. Francisco Iacobelli from Health Informatics and Data Science brings expertise in dialogue systems, natural language processing for health applications, and addressing health disparities through technology, aligning perfectly with my goal of making AI accessible to health practitioners in resource-constrained settings.

From Computer Science, Dr. Dmitry Dligach's pioneering work in clinical NLP, particularly his research on domain-specific pre-training strategies (EntityBERT) and uncertainty estimation in medical LLMs, provides the technical foundation for advancing language models in health contexts. His methodologies for adapting LLMs to understand medical terminology offer a roadmap for extending these approaches to epidemiological applications. Dr. Mohammed Abuhamad's expertise in AI security and adversarial robustness addresses a critical need—ensuring these AI systems remain reliable and secure when deployed in settings where computational resources are limited and errors have serious consequences.

Working with my co-supervisors—Dr. Ozodiegwu's domain expertise and Dr. Iacobelli's NLP focus—I have a strong foundation bridging application domains and technology. I am eager to complement this team with Professor Dligach and/or Professor Abuhamad, whose expertise in clinical NLP and AI security would strengthen the technical dimensions of my research. This interdisciplinary approach will enable me to develop AI systems that are both technically rigorous and grounded in real-world constraints.

My research vision centers on making language models accessible to domain experts through improved usability and deployment strategies. I plan to investigate specific technical approaches including few-shot learning for rapid domain adaptation, retrieval-augmented generation for knowledge grounding, and multi-agent architectures for complex reasoning tasks. Long-term, I aspire to contribute to research that bridges AI capabilities and practical accessibility, whether in academia or industry research labs.

My background—from rural Ghana through engineering studies in South Africa to AI research in Chicago—provides unique perspectives on technology's potential to address global inequities. This journey, including overcoming personal challenges, motivates my interest in making AI accessible beyond well-resourced settings. Through doctoral studies at Loyola, I want to explore how we can bridge the gap between advanced AI capabilities and practical usability, particularly for communities and domains that have been underserved by current technology. I am ready to contribute to Loyola's research community while pursuing questions that could help make AI tools more broadly accessible and beneficial.
