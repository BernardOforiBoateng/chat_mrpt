# Dr. Mohammed Abuhamad - PhD Meeting Preparation Guide

## Background & Credentials
- **Position**: Assistant Professor, Computer Science, Loyola University Chicago
- **Unique Qualification**: Has TWO PhDs!
  - Ph.D. in Computer Science (University of Central Florida, 2020)
  - Ph.D. in Electrical & Computer Engineering (INHA University, Korea, 2020)
- **Lab**: Directs the **AI for Secure Computing Research Lab (AISeC)**
- **Citations**: 1,160+ on Google Scholar
- **Office**: 213 Doyle Center
- **Office Hours**: 
  - Monday: 3:00 - 5:00 PM
  - Friday: 9:00 - 11:00 AM
- **Email**: mabuhamad@luc.edu
- **Phone**: 773-508-3557

## Research Areas (Critical for Your Discussion)

### Primary Focus: AI Security & Robustness
- **Adversarial Machine Learning** - Making AI models resistant to attacks
- **Model Privacy** - Preventing data leakage from trained models
- **Robustness in Critical Systems** - Autonomous vehicles, IoT, healthcare

### Recent Papers to Reference:
1. **"SingleADV"** (IEEE TIFS 2024) - Attacks on interpretable AI systems
2. **"Robust Federated Learning"** (2024) - Security in distributed AI
3. **"Hardening Interpretable Deep Learning Systems"** (2023)

## üî¥ KEY CONNECTIONS TO YOUR WORK

### 1. Security for Deployed AI Systems
- Your ChatMRPT deploys in resource-constrained Nigerian health facilities
- His expertise: Making AI secure in adversarial/unreliable environments
- **Talking point**: "How do we ensure ChatMRPT remains robust when deployed in settings with limited oversight?"

### 2. Privacy-Preserving AI
- Your concern: Health data privacy in epidemiological analysis
- His work: Preventing membership inference and data leakage
- **Talking point**: "How can we ensure patient privacy when AI analyzes sensitive health data?"

### 3. Interpretable AI Security
- Your need: Health officials must trust AI recommendations
- His paper on SingleADV: Attacks on interpretable systems
- **Talking point**: "How do we balance interpretability with security in health AI?"

### 4. Federated Learning Applications
- Your vision: Multiple health facilities sharing insights without sharing data
- His 2024 paper on robust federated learning
- **Talking point**: "Could federated learning help aggregate insights across Nigerian states?"

## üí¨ CONVERSATION STARTERS

### About Your Class Experience:
"I really enjoyed Big Data Analytics (COMP 458) with you last spring. The distributed computing concepts were essential when I scaled ChatMRPT to handle 15GB datasets."

### About His Double PhD:
"I'm fascinated by your dual expertise in CS and ECE. How does the hardware perspective inform your approach to AI security?"

### About Resource Constraints:
"Your work on IoT security seems relevant to my challenge - deploying AI in settings with unreliable internet and limited computing power."

## üìã QUESTIONS TO ASK

### Research-Related:
- "How might adversarial robustness techniques apply to NLP models in low-resource languages?"
- "What are the main security vulnerabilities when deploying conversational AI in healthcare?"
- "Could your work on model privacy help with HIPAA compliance for health AI systems?"

### PhD Supervision:
- "What kind of research questions in AI security for global health would excite you?"
- "How does your AISeC lab operate? Do students collaborate on projects?"
- "What's your mentorship style for PhD students?"

## üéØ YOUR PITCH POINTS

### 1. Unique Application Domain:
- "I'm bringing real-world deployment challenges from Nigerian health systems"
- "Security isn't just technical - it's about trust in resource-constrained communities"

### 2. Technical Alignment:
- "ChatMRPT already uses distributed caching and lazy loading - scalability patterns you teach"
- "I'm interested in adversarial robustness for multi-lingual health AI"

### 3. Research Vision Connection:
- "Your expertise in securing AI for critical systems perfectly complements my goal of making AI accessible in global health"
- "I want to explore how security and accessibility intersect - not just making AI work, but making it trustworthy"

## ‚ö†Ô∏è THINGS TO KNOW

- He has **high standards** (students mention this) but is very knowledgeable
- Recently received **$3.8M NSF CyberCorps grant** - potential funding opportunity
- Published in top venues (ACM CCS, IEEE TIFS) - shows research quality expectations
- Interested in **real-world applications** not just theory

## üìù MATERIALS TO BRING
1. Your SOP (emphasize the security/robustness aspects)
2. ChatMRPT technical architecture diagram (show distributed system design)
3. Questions about adversarial robustness in NLP
4. Ideas about security challenges in global health AI

## üöÄ POTENTIAL COLLABORATION ANGLES

### 1. Secure Multi-Agent Systems
Combining your AI agents interest with his security expertise

### 2. Privacy-Preserving Health Analytics
HIPAA-compliant AI for epidemiology

### 3. Robust NLP for Low-Resource Settings
Adversarial training for African languages

### 4. Federated Learning for Health
Distributed training across health facilities

## üéØ KEY TAKEAWAY FOR TOMORROW

Dr. Abuhamad's expertise in **AI security and robustness** is PERFECT for your work because:
- ChatMRPT needs to be **secure** (handling sensitive health data)
- It needs to be **robust** (working in unreliable environments)  
- It needs to be **trustworthy** (health officials must trust its recommendations)

**Your best angle**: Position yourself as someone bringing **real-world deployment challenges from global health** that need his security expertise to solve. You're not just interested in AI security theory - you have an actual system (ChatMRPT) facing these challenges in the field.

**Remember**: Mention you were in his COMP 458 class - that existing relationship is valuable!

---

*Good luck with your meeting tomorrow!*