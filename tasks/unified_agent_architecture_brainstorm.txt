================================================================================
CHATMRPT UNIFIED AGENT ARCHITECTURE - COMPREHENSIVE BRAINSTORM
================================================================================
Date: October 3, 2025
Status: Investigation & Planning Phase
Goal: Make DataAnalysisAgent the single source of truth for ALL conversations

================================================================================
EXECUTIVE SUMMARY
================================================================================

CURRENT PROBLEM:
- THREE separate routing systems fighting for control
- Duplicate conversation handling logic across multiple files
- Agent exists but only used for TPR workflow in Data Analysis V3 tab
- RequestInterpreter handles main chat but is monolithic (1743 lines)
- Arena system adds third routing layer for conversational queries

VISION:
- DataAnalysisAgent becomes the ONLY conversational interface
- Agent active throughout ALL phases: Upload â†’ TPR â†’ Risk â†’ ITN â†’ Questions
- All tools available to agent at all times (phase-aware execution)
- Single Flask route â†’ Agent â†’ Tools (no routing logic in Flask)
- Arena integrated as agent capability, not separate system

BENEFITS:
- Eliminate routing complexity (3 systems â†’ 1 agent)
- Consistent UX across all workflow phases
- Easier to add new capabilities (just add tools)
- Agent learns from conversation history
- Maintainable codebase (fewer decision points)

================================================================================
PART 1: CURRENT ARCHITECTURE ANALYSIS
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CURRENT THREE-WAY ROUTING SYSTEM                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. DATA ANALYSIS V3 ROUTE (/api/v1/data-analysis/chat)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   File: app/web/routes/data_analysis_v3_routes.py (680 lines)
   Entry: Line 331 - @data_analysis_v3_bp.route('/api/v1/data-analysis/chat')

   FLOW:
   User Message â†’ TPR Keyword Check â†’ TPR Workflow Handler
                                    â†“
                             Keyword Found? â†’ TPR handles selection
                                    â†“
                             No Keyword? â†’ Route to DataAnalysisAgent

   COMPONENTS:
   - TPRWorkflowHandler (1543 lines) - State machine for TPR 3-stage workflow
   - DataAnalysisAgent (377 lines) - LangGraph agent with OpenAI gpt-4o
   - ConversationStage Enum - Tracks workflow progression
   - DataAnalysisStateManager - File-based state persistence

   TOOLS AVAILABLE:
   - analyze_data (Python execution via LangGraph)
   - analyze_tpr_data (TPR calculation via LangGraph)

   KEYWORDS DETECTION:
   - TPR start: "tpr", "start tpr workflow", "run tpr"
   - Confirmation: "yes", "continue", "proceed", "ok"
   - Facility: "primary", "secondary", "tertiary", "all"
   - Age group: "u5", "o5", "pw", "all"

   ISSUES:
   - Complex nested routing (lines 388-679)
   - Agent only called when keyword matching fails
   - Agent has limited tools (only 2)
   - After TPR completes, transitions OUT of this route


2. MAIN CHAT ROUTE (/analyze with streaming)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   File: app/web/routes/analysis_routes.py (line 1838)
   Entry: Streaming endpoint for main ChatMRPT interface

   FLOW:
   User Message â†’ Mistral Router â†’ Arena (conversational) OR RequestInterpreter (tools)
                                                              â†“
                                                    ToolRunner â†’ Execute tool

   COMPONENTS:
   - RequestInterpreter (1743 lines) - Massive orchestrator class
   - LLMOrchestrator (~200 lines) - Streaming tool execution
   - ToolRunner (245 lines) - Tool normalization & execution
   - Mistral Router - Intent classification (can_answer vs needs_tools)

   TOOLS AVAILABLE (11 total):
   - execute_sql_query
   - execute_data_query
   - run_malaria_risk_analysis
   - run_itn_planning
   - create_vulnerability_map
   - create_pca_map
   - create_box_plot
   - create_scatter_plot
   - run_data_quality_check
   - explain_analysis_methodology
   - create_settlement_map

   ROUTING LOGIC (line 700-760):
   - Short messages (â‰¤3 words) â†’ Auto-route to Arena
   - Mistral says "can_answer" â†’ Arena
   - Mistral says "needs_tools" â†’ RequestInterpreter
   - Mistral says "needs_clarification" â†’ Ask user to choose

   ISSUES:
   - RequestInterpreter is monolithic (1743 lines, 50+ methods)
   - Duplicate logic with Data Analysis V3 agent
   - Tools not available to agent (only to RequestInterpreter)
   - Complex decision tree before executing anything


3. ARENA SYSTEM (Multi-Model Tournament)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   File: app/core/arena_manager.py
   Route: /api/vote_arena (line 1108 in analysis_routes.py)

   FLOW:
   Conversational Query â†’ Arena Manager â†’ Parallel model calls â†’ Show responses â†’ User votes

   MODELS:
   - Model D: OpenAI gpt-4o (champion)
   - Model C: OpenAI gpt-4o-mini
   - Model B: Ollama llama3.1:latest
   - Model A: Ollama mistral:latest

   FEATURES:
   - Progressive tournament (multi-round elimination)
   - Session context awareness (knows about uploaded data)
   - Redis-backed storage for multi-worker support
   - Latency tracking
   - Interaction logging

   INTEGRATION POINTS:
   - Called from analysis_routes.py when use_arena=True (line 764)
   - Uses arena_system_prompt.py for base prompt
   - Uses arena_context_manager.py for session context
   - Stores battles in Redis with ArenaStorageManager

   ISSUES:
   - Separate from agent (could be agent capability)
   - Arena responses don't have tool access
   - Can't handle "show me a visualization" after answering question
   - User has to explicitly choose Arena vs Tools path

================================================================================
PART 2: FILE-BY-FILE RESPONSIBILITY MATRIX
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FILE                                    â”‚ LINES â”‚ RESPONSIBILITY          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RequestInterpreter (request_interpreter.py)                               â”‚
â”‚                                         â”‚ 1743  â”‚ - Message processing    â”‚
â”‚                                         â”‚       â”‚ - Tool orchestration    â”‚
â”‚                                         â”‚       â”‚ - Session context load  â”‚
â”‚                                         â”‚       â”‚ - System prompt build   â”‚
â”‚                                         â”‚       â”‚ - Streaming responses   â”‚
â”‚                                         â”‚       â”‚ STATUS: ðŸ”´ RETIRE       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DataAnalysisAgent (agent.py)                                              â”‚
â”‚                                         â”‚  377  â”‚ - LangGraph workflow    â”‚
â”‚                                         â”‚       â”‚ - Python code execution â”‚
â”‚                                         â”‚       â”‚ - Data summarization    â”‚
â”‚                                         â”‚       â”‚ - Conversation history  â”‚
â”‚                                         â”‚       â”‚ STATUS: âœ… EXPAND       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TPRWorkflowHandler (tpr_workflow_handler.py)                              â”‚
â”‚                                         â”‚ 1543  â”‚ - TPR state machine     â”‚
â”‚                                         â”‚       â”‚ - Keyword detection     â”‚
â”‚                                         â”‚       â”‚ - Stage progression     â”‚
â”‚                                         â”‚       â”‚ - Visualization gen     â”‚
â”‚                                         â”‚       â”‚ STATUS: ðŸŸ¡ CONVERT      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ToolRunner (tool_runner.py)                                               â”‚
â”‚                                         â”‚  245  â”‚ - Tool schema generationâ”‚
â”‚                                         â”‚       â”‚ - Tool execution        â”‚
â”‚                                         â”‚       â”‚ - Result normalization  â”‚
â”‚                                         â”‚       â”‚ - Fallback handling     â”‚
â”‚                                         â”‚       â”‚ STATUS: âœ… WRAP TOOLS   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LLMOrchestrator (llm_orchestrator.py)                                     â”‚
â”‚                                         â”‚ ~200  â”‚ - Streaming tool calls  â”‚
â”‚                                         â”‚       â”‚ - Session ID injection  â”‚
â”‚                                         â”‚       â”‚ STATUS: ðŸŸ¡ MAYBE RETIRE â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ArenaManager (arena_manager.py)                                           â”‚
â”‚                                         â”‚  600+ â”‚ - Model tournaments     â”‚
â”‚                                         â”‚       â”‚ - Response caching      â”‚
â”‚                                         â”‚       â”‚ - User voting           â”‚
â”‚                                         â”‚       â”‚ - Redis storage         â”‚
â”‚                                         â”‚       â”‚ STATUS: âœ… INTEGRATE    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SessionContextService (session_context_service.py)                        â”‚
â”‚                                         â”‚  ~150 â”‚ - Load session data     â”‚
â”‚                                         â”‚       â”‚ - CSV reading           â”‚
â”‚                                         â”‚       â”‚ STATUS: âœ… REUSE        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PromptBuilder (prompt_builder.py)                                         â”‚
â”‚                                         â”‚  ~100 â”‚ - System prompt build   â”‚
â”‚                                         â”‚       â”‚ - Context formatting    â”‚
â”‚                                         â”‚       â”‚ STATUS: âœ… REUSE        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DataAnalysisStateManager (state_manager.py)                               â”‚
â”‚                                         â”‚  475  â”‚ - Workflow stage track  â”‚
â”‚                                         â”‚       â”‚ - File-based persistenceâ”‚
â”‚                                         â”‚       â”‚ - TPR selections storageâ”‚
â”‚                                         â”‚       â”‚ STATUS: âœ… REUSE        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL LINES TO RETIRE: ~1743 (RequestInterpreter)
TOTAL LINES TO CONVERT: ~1543 (TPR to tools)
TOTAL LINES TO REUSE: ~1000 (existing utilities)
TOTAL LINES TO EXPAND: ~377 (Agent)

================================================================================
PART 3: UNIFIED AGENT ARCHITECTURE DESIGN
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PROPOSED UNIFIED FLOW                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  USER MESSAGE   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  FLASK ROUTE    â”‚
                            â”‚  (Simplified)   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  DataAnalysisAgent      â”‚
                            â”‚  (Single Entry Point)   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                â”‚                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
            â”‚  Phase Check â”‚  â”‚ Tool Check â”‚  â”‚Arena Check â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                â”‚                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚       AGENT DECIDES BASED ON CONTEXT          â”‚
            â”‚  - Current workflow phase (TPR/Risk/ITN)     â”‚
            â”‚  - Available data (CSV/Shapefile/Analysis)   â”‚
            â”‚  - User intent (question vs action)          â”‚
            â”‚  - Conversation history                      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚               â”‚          â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”
    â”‚TPR Toolâ”‚  â”‚Risk Toolâ”‚ â”‚ ITN Tool  â”‚  â”‚Viz Tool â”‚ â”‚Arena  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚               â”‚          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  TOOL RESULT   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  AGENT FORMATS â”‚
                        â”‚  & RESPONDS    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  USER RESPONSE â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


KEY PRINCIPLE: Agent is ALWAYS active, makes ALL decisions

================================================================================
PART 4: AGENT ENHANCEMENT PLAN
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENHANCED DATAANALYSISAGENT                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

class DataAnalysisAgent:
    """
    Unified conversational agent for ALL ChatMRPT interactions.

    Handles:
    - Data upload conversations
    - TPR workflow (state, facility, age group selection)
    - Risk analysis requests
    - ITN planning
    - Data queries (SQL, natural language)
    - Visualizations
    - Methodology explanations
    - Arena-style model comparisons
    """

    def __init__(self, session_id: str):
        # Session context
        self.session_id = session_id
        self.load_session_context()

        # Workflow state
        self.state_manager = DataAnalysisStateManager(session_id)
        self.current_phase = self.state_manager.get_workflow_stage()

        # LLM configuration
        self.llm = ChatOpenAI(
            model="gpt-4o",  # Primary model
            temperature=0.7,
            max_tokens=2000
        )

        # Tools registration
        self.tools = self._register_all_tools()

        # Arena integration
        self.arena_manager = ArenaManager()
        self.arena_enabled = True

        # System prompt (phase-aware)
        self.system_prompt = self._build_phase_aware_prompt()

        # Bind tools to LLM
        self.model = self.llm.bind_tools(self.tools)

        # LangGraph workflow
        self.graph = self._build_graph()

    def _register_all_tools(self) -> List:
        """Register ALL available tools for ALL phases."""
        return [
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # DATA ANALYSIS & QUERY TOOLS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            analyze_data_python,          # Execute Python code
            query_data_sql,               # SQL queries
            query_data_natural_language,  # NL to SQL
            check_data_quality,           # Data validation

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # TPR WORKFLOW TOOLS (converted from handler)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            analyze_tpr_data,             # Full TPR calculation
            select_tpr_state,             # State selection
            select_facility_level,        # Facility selection
            select_age_group,             # Age group selection
            calculate_ward_tpr,           # Ward-level TPR calc

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # RISK ANALYSIS TOOLS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            run_risk_analysis,            # Dual-method analysis
            run_composite_scoring,        # Composite only
            run_pca_analysis,             # PCA only

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # VISUALIZATION TOOLS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            create_vulnerability_map,     # Choropleth map
            create_pca_map,               # PCA results map
            create_tpr_distribution_map,  # TPR map
            create_box_plot,              # Box plot
            create_scatter_plot,          # Scatter plot
            create_correlation_heatmap,   # Heatmap
            create_histogram,             # Distribution

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ITN PLANNING TOOLS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            plan_itn_distribution,        # ITN allocation
            create_itn_allocation_map,    # ITN map

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # METHODOLOGY & HELP TOOLS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            explain_methodology,          # Method explanation
            explain_tpr_concept,          # TPR explanation
            explain_composite_scoring,    # Composite explanation
            explain_pca,                  # PCA explanation

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ARENA INTEGRATION (NEW)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            start_model_comparison,       # Trigger arena
            get_arena_response,           # Get model responses
        ]

    def _build_phase_aware_prompt(self) -> str:
        """Build system prompt based on current workflow phase."""

        base_prompt = """You are ChatMRPT, an AI assistant for malaria risk analysis.

You help users through a complete analysis workflow:
1. Data upload and validation
2. TPR (Test Positivity Rate) calculation workflow
3. Environmental risk analysis (Composite + PCA methods)
4. ITN (bed net) distribution planning

You have access to multiple tools for data analysis, visualization, and explanation."""

        # Add phase-specific context
        if self.current_phase == ConversationStage.INITIAL:
            phase_context = """
CURRENT PHASE: Initial data upload
- User has just uploaded data or is about to
- Ask if they want to start TPR workflow
- Can answer general questions about the process
"""

        elif self.current_phase == ConversationStage.TPR_STATE_SELECTION:
            phase_context = """
CURRENT PHASE: TPR State Selection
- User needs to select which state to analyze
- Available states: [from context]
- Use select_tpr_state tool to record their choice
- Can explain what TPR is and why we need it
"""

        elif self.current_phase == ConversationStage.TPR_FACILITY_LEVEL:
            phase_context = """
CURRENT PHASE: TPR Facility Level Selection
- User needs to select facility level (primary/secondary/tertiary/all)
- Use select_facility_level tool to record their choice
- Can show facility distribution visualizations
- Can explain differences between facility levels
"""

        elif self.current_phase == ConversationStage.TPR_AGE_GROUP:
            phase_context = """
CURRENT PHASE: TPR Age Group Selection
- User needs to select age group (u5/o5/pw/all)
- Use select_age_group tool to record their choice
- Can show age group distribution visualizations
- Can explain why age matters for malaria risk
"""

        elif self.current_phase == ConversationStage.TPR_COMPLETED_AWAITING_CONFIRMATION:
            phase_context = """
CURRENT PHASE: TPR Complete, Risk Analysis Ready
- TPR calculation is complete
- Data is prepared for risk analysis
- Ask if user wants to proceed to risk analysis
- Can show TPR results and distribution map
- Can answer questions about TPR findings
"""

        elif self.current_phase == ConversationStage.RISK_ANALYSIS:
            phase_context = """
CURRENT PHASE: Risk Analysis Available
- User can run dual-method risk analysis (Composite + PCA)
- Can create various visualizations
- Can query specific wards or variables
- Can explain analysis methodology
"""

        elif self.current_phase == ConversationStage.ITN_PLANNING:
            phase_context = """
CURRENT PHASE: ITN Planning Available
- Risk analysis is complete
- User can plan ITN distribution based on risk rankings
- Can create ITN allocation maps
- Can answer questions about intervention strategies
"""

        else:
            phase_context = ""

        # Add session context
        session_context = self._get_session_context_summary()

        # Add available tools context
        tools_context = f"""
AVAILABLE TOOLS: You have {len(self.tools)} tools available
- {', '.join([t.name for t in self.tools[:10]])}
- ... and {len(self.tools) - 10} more

Choose the appropriate tool based on user intent and current phase.
"""

        # Combine all context
        full_prompt = f"{base_prompt}\n\n{phase_context}\n\n{session_context}\n\n{tools_context}"

        return full_prompt

    async def analyze(self, message: str, use_arena: bool = None) -> Dict[str, Any]:
        """
        Main entry point for message analysis.

        Args:
            message: User's message
            use_arena: Optional flag to force arena mode

        Returns:
            Response dict with message, visualizations, etc.
        """

        # STEP 1: Decide if Arena should be used
        if use_arena is None:
            use_arena = self._should_use_arena(message)

        # STEP 2: Arena path (conversational, comparison mode)
        if use_arena:
            return await self._handle_with_arena(message)

        # STEP 3: Tool path (data analysis, workflow actions)
        else:
            return await self._handle_with_tools(message)

    def _should_use_arena(self, message: str) -> bool:
        """
        Decide if Arena mode should be used.

        Arena is used for:
        - General questions about malaria, methodology, concepts
        - Clarification requests
        - Conversations that don't require data manipulation

        Tools are used for:
        - Data queries (show me wards, what are the values)
        - Analysis execution (run risk analysis)
        - Visualizations (create a map, show distribution)
        - Workflow actions (select facility level, calculate TPR)
        """

        # Use LLM to classify intent
        intent_prompt = f"""Classify this user message:

Message: "{message}"

Context: {self._get_session_context_summary()}

Should this be handled with:
A) ARENA (conversational, explanatory, general questions)
B) TOOLS (data manipulation, analysis, visualization)

Respond with just 'ARENA' or 'TOOLS'."""

        response = self.llm.invoke(intent_prompt)
        decision = response.content.strip().upper()

        return decision == 'ARENA'

    async def _handle_with_arena(self, message: str) -> Dict[str, Any]:
        """Handle message using Arena (multi-model comparison)."""

        # Start progressive battle
        battle_info = await self.arena_manager.start_progressive_battle(
            message,
            session_id=self.session_id,
            system_prompt=self.system_prompt
        )

        # Get responses from first pair
        responses = await self.arena_manager.get_all_model_responses(
            battle_info['battle_id']
        )

        return {
            'success': True,
            'message': 'Arena mode activated. Compare responses:',
            'arena_mode': True,
            'battle_id': battle_info['battle_id'],
            'model_a': battle_info['model_a'],
            'model_b': battle_info['model_b'],
            'response_a': responses['a'],
            'response_b': responses['b'],
            'session_id': self.session_id
        }

    async def _handle_with_tools(self, message: str) -> Dict[str, Any]:
        """Handle message using tools (LangGraph workflow)."""

        # Prepare state
        state = {
            'messages': [HumanMessage(content=message)],
            'input_data': self._get_input_data(),
            'session_id': self.session_id,
            'current_phase': self.current_phase,
        }

        # Run through LangGraph
        result = await self.graph.ainvoke(state)

        # Extract response
        final_message = result['messages'][-1]

        # Check for tool calls and results
        visualizations = self._extract_visualizations(result)
        download_links = self._extract_download_links(result)

        return {
            'success': True,
            'message': final_message.content,
            'visualizations': visualizations,
            'download_links': download_links,
            'session_id': self.session_id,
            'tools_used': self._get_tools_used(result)
        }

================================================================================
PART 5: TOOL CONVERSION STRATEGY
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CONVERTING EXISTING TOOLS TO LANGGRAPH FORMAT                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CURRENT STATE:
- RequestInterpreter has 11 tools as methods (_run_malaria_risk_analysis, etc.)
- ToolRunner wraps these as fallbacks
- Tools accessed via ToolRunner.execute(name, args_json)

TARGET STATE:
- All tools as LangGraph-compatible @tool decorated functions
- Agent binds tools via llm.bind_tools(self.tools)
- LangGraph ToolNode handles execution

CONVERSION PATTERN:
==================

# BEFORE (RequestInterpreter method):
class RequestInterpreter:
    def _run_malaria_risk_analysis(self, session_id: str, method: str = "dual"):
        """Run risk analysis..."""
        # Implementation here
        return result

# AFTER (LangGraph tool):
from langchain_core.tools import tool

@tool
def run_risk_analysis(session_id: str, method: str = "dual") -> dict:
    """Run complete malaria risk analysis.

    Use this when user requests:
    - Risk analysis
    - Vulnerability assessment
    - Calculate malaria risk scores
    - Dual-method analysis (Composite + PCA)

    Args:
        session_id: Session identifier
        method: 'dual' (both methods), 'composite', or 'pca'

    Returns:
        Dict with rankings, maps, and analysis results
    """
    # Reuse existing implementation
    from app.core.request_interpreter import RequestInterpreter
    from app.services.container import ServiceContainer

    # Get services
    services = ServiceContainer()
    interpreter = RequestInterpreter(
        services.llm_manager,
        services.data_service,
        services.analysis_service,
        services.visualization_service
    )

    # Call existing method
    return interpreter._run_malaria_risk_analysis(session_id, method)


TOOLS TO CONVERT:
=================

1. âœ… Data Query Tools (already working as fallbacks, just wrap):
   - execute_sql_query â†’ query_data_sql
   - execute_data_query â†’ query_data_natural_language

2. âœ… Analysis Tools:
   - _run_malaria_risk_analysis â†’ run_risk_analysis
   - _run_data_quality_check â†’ check_data_quality

3. âœ… Visualization Tools:
   - _create_vulnerability_map â†’ create_vulnerability_map
   - _create_pca_map â†’ create_pca_map
   - _create_box_plot â†’ create_box_plot
   - _create_scatter_plot â†’ create_scatter_plot
   - _create_variable_distribution â†’ create_variable_distribution

4. âœ… ITN Planning:
   - _run_itn_planning â†’ plan_itn_distribution

5. âœ… Methodology:
   - _explain_analysis_methodology â†’ explain_methodology

6. ðŸ”§ TPR Workflow (requires breaking apart handler):
   - TPRWorkflowHandler.handle_state_selection â†’ select_tpr_state
   - TPRWorkflowHandler.handle_facility_selection â†’ select_facility_level
   - TPRWorkflowHandler.handle_age_group_selection â†’ select_age_group
   - TPRWorkflowHandler.calculate_tpr â†’ calculate_ward_tpr

7. ðŸ†• Arena Integration (new tools):
   - start_model_comparison â†’ Trigger arena battle
   - get_arena_response â†’ Get specific model's response


EXAMPLE TOOL WRAPPER FILE:
===========================

File: app/data_analysis_v3/tools/risk_analysis_tools.py

from langchain_core.tools import tool
from typing import Dict, Any, Optional

@tool
def run_risk_analysis(session_id: str, method: str = "dual") -> dict:
    """Run complete malaria risk analysis using composite and/or PCA methods.

    This tool executes the full risk analysis pipeline:
    1. Loads prepared data with TPR + environmental variables
    2. Runs analysis (composite scoring, PCA, or both)
    3. Ranks wards by vulnerability
    4. Generates interactive maps
    5. Creates unified dataset with rankings

    When to use:
    - User asks to "run risk analysis"
    - User wants to "analyze malaria risk"
    - User requests "vulnerability assessment"
    - User says "calculate risk scores"

    Args:
        session_id: Session identifier for data loading
        method: Analysis method to use
            - 'dual': Both composite and PCA (recommended)
            - 'composite': Composite scoring only
            - 'pca': Principal Component Analysis only

    Returns:
        Dict containing:
            - status: 'success' or 'error'
            - message: Human-readable summary
            - rankings: Top/bottom wards by risk
            - visualizations: List of map URLs
            - download_links: CSV/Excel file links
            - data: Additional analysis metadata
    """
    from app.core.request_interpreter import get_singleton_interpreter

    interpreter = get_singleton_interpreter()
    result = interpreter._run_malaria_risk_analysis(session_id, method)

    return result


@tool
def create_vulnerability_map(
    session_id: str,
    method: str = "composite",
    variable: Optional[str] = None
) -> dict:
    """Create an interactive vulnerability map.

    When to use:
    - User asks to "show vulnerability map"
    - User wants to "visualize risk scores"
    - User requests "map of high-risk areas"

    Args:
        session_id: Session identifier
        method: 'composite' or 'pca' results to map
        variable: Optional specific variable to map

    Returns:
        Dict with map URL and metadata
    """
    from app.core.request_interpreter import get_singleton_interpreter

    interpreter = get_singleton_interpreter()
    result = interpreter._create_vulnerability_map(
        session_id,
        method=method,
        variable=variable
    )

    return result


# Export all tools
__all__ = [
    'run_risk_analysis',
    'create_vulnerability_map',
]

================================================================================
PART 6: TPR WORKFLOW HANDLER CONVERSION
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TPR WORKFLOW: FROM HANDLER TO TOOLS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CURRENT TPR WORKFLOW HANDLER:
==============================
File: app/data_analysis_v3/core/tpr_workflow_handler.py (1543 lines)

Key Methods:
- start_workflow() â†’ Initial TPR introduction
- handle_state_selection(message) â†’ Process state choice
- handle_facility_selection(message) â†’ Process facility choice
- handle_age_group_selection(message) â†’ Process age group choice
- calculate_tpr() â†’ Run TPR calculation
- extract_facility_level(message) â†’ Keyword detection
- extract_age_group(message) â†’ Keyword detection

Current Flow:
1. User says "start TPR"
2. Handler shows intro, waits for confirmation
3. User says "yes"
4. Handler shows state options (if multiple)
5. User selects state
6. Handler shows facility options
7. User selects facility level
8. Handler shows age group options
9. User selects age group
10. Handler calculates TPR, shows map
11. Handler prepares data for risk analysis

PROBLEM: Handler contains routing logic (keyword detection + fallback to agent)

SOLUTION: Convert to tools, let agent handle routing via prompting

PROPOSED TPR TOOLS:
===================

@tool
def start_tpr_workflow(session_id: str) -> dict:
    """Initialize the TPR workflow.

    This shows the user an introduction to TPR analysis and
    asks for confirmation to proceed.

    When to use:
    - User says "start TPR"
    - User asks "run TPR workflow"
    - User wants to "calculate test positivity rate"

    Returns:
        Dict with intro message and next steps
    """
    from app.data_analysis_v3.core.state_manager import DataAnalysisStateManager
    from app.data_analysis_v3.tpr.workflow_manager import TPRWorkflowHandler

    state_manager = DataAnalysisStateManager(session_id)
    handler = TPRWorkflowHandler(session_id, state_manager, None)

    return handler.start_workflow()


@tool
def select_tpr_state(session_id: str, state_name: str) -> dict:
    """Record user's state selection for TPR analysis.

    When to use:
    - User has selected which state to analyze
    - After showing available states

    Args:
        session_id: Session identifier
        state_name: Name of the state (e.g., "Kano", "Lagos")

    Returns:
        Dict with confirmation and next step (facility selection)
    """
    from app.data_analysis_v3.core.state_manager import DataAnalysisStateManager, ConversationStage

    state_manager = DataAnalysisStateManager(session_id)
    state_manager.save_tpr_selection('state', state_name)
    state_manager.update_workflow_stage(ConversationStage.TPR_FACILITY_LEVEL)

    # Load data and show facility options
    # ... (implementation)

    return {
        'success': True,
        'message': f'State selected: {state_name}. Now choose facility level...',
        'next_stage': 'facility_selection'
    }


@tool
def select_facility_level(session_id: str, level: str) -> dict:
    """Record user's facility level selection.

    When to use:
    - User has chosen facility level (primary/secondary/tertiary/all)

    Args:
        session_id: Session identifier
        level: One of 'primary', 'secondary', 'tertiary', 'all'

    Returns:
        Dict with confirmation and age group selection prompt
    """
    from app.data_analysis_v3.core.state_manager import DataAnalysisStateManager, ConversationStage

    state_manager = DataAnalysisStateManager(session_id)
    state_manager.save_tpr_selection('facility_level', level)
    state_manager.update_workflow_stage(ConversationStage.TPR_AGE_GROUP)

    # Show age group options
    # ... (implementation)

    return {
        'success': True,
        'message': f'Facility level selected: {level}. Now choose age group...',
        'next_stage': 'age_group_selection'
    }


@tool
def select_age_group(session_id: str, age_group: str) -> dict:
    """Record user's age group selection and trigger TPR calculation.

    When to use:
    - User has chosen age group (u5/o5/pw/all)
    - This is the final selection, triggers calculation

    Args:
        session_id: Session identifier
        age_group: One of 'u5' (under 5), 'o5' (over 5), 'pw' (pregnant women), 'all'

    Returns:
        Dict with TPR results, map, and transition to risk analysis
    """
    from app.data_analysis_v3.core.state_manager import DataAnalysisStateManager
    from app.data_analysis_v3.tpr.data_analyzer import TPRDataAnalyzer

    state_manager = DataAnalysisStateManager(session_id)
    state_manager.save_tpr_selection('age_group', age_group)

    # Run TPR calculation
    tpr_analyzer = TPRDataAnalyzer()
    selections = state_manager.get_tpr_selections()

    result = tpr_analyzer.calculate_ward_tpr(
        session_id,
        state=selections['state'],
        facility_level=selections['facility_level'],
        age_group=age_group
    )

    # Prepare for risk analysis
    # ... (create raw_data.csv, raw_shapefile.zip)

    state_manager.update_workflow_stage(ConversationStage.TPR_COMPLETED_AWAITING_CONFIRMATION)

    return {
        'success': True,
        'message': f'TPR calculated for {age_group}! Results ready.',
        'tpr_map': result['map_url'],
        'next_step': 'risk_analysis_available'
    }


BENEFIT OF TOOL APPROACH:
=========================

BEFORE (Handler routing):
- Handler checks keywords: if "primary" in message.lower()
- If match â†’ handle selection
- If no match â†’ route to agent with context

AFTER (Agent decides):
- Agent sees: "User is in facility selection stage. Valid options: primary, secondary, tertiary, all."
- Agent interprets message: "I want to focus on primary care facilities"
- Agent calls: select_facility_level(session_id, "primary")
- Agent explains: "I've selected primary care facilities for the analysis."

WHY THIS IS BETTER:
1. Agent handles natural language variations ("primary care" vs "primary facilities" vs "primary")
2. Agent can ask clarifying questions if ambiguous
3. Agent can explain what it's doing
4. No rigid keyword matching
5. Agent learns from conversation history

================================================================================
PART 7: ARENA INTEGRATION STRATEGY
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ARENA AS AGENT CAPABILITY                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CURRENT ARENA SYSTEM:
=====================
- Separate routing decision (Mistral Router â†’ Arena or Tools)
- Arena called from analysis_routes.py line 764
- Progressive tournament with 4 models (D, C, B, A)
- User votes on responses, builds ranking
- Results stored in Redis

PROBLEMS WITH CURRENT APPROACH:
================================
1. Arena responses have NO tool access
   - Can't show visualizations
   - Can't query data
   - Can't calculate anything

2. Hard boundary between Arena and Tools
   - User must choose upfront
   - Can't switch mid-conversation
   - Arena can't say "let me show you a map"

3. Duplicate conversation handling
   - Arena has its own system prompt
   - Arena has its own context manager
   - Separate from agent's context

PROPOSED INTEGRATION:
=====================

Arena becomes a CAPABILITY of the agent, not a separate system.

Agent decides when to use Arena:
- Conversational questions â†’ Start arena comparison
- Explanation requests â†’ Start arena comparison
- Methodology questions â†’ Start arena comparison

Agent can COMBINE Arena with Tools:
- Arena answers question
- Agent offers: "Would you like to see a visualization?"
- User says yes
- Agent calls visualization tool
- User gets both: explanation + chart

IMPLEMENTATION:
===============

1. Arena Tool for Agent:

@tool
def compare_model_responses(message: str, session_id: str) -> dict:
    """Get responses from multiple models for comparison.

    Use this when:
    - User asks an open-ended question
    - Multiple perspectives would be valuable
    - User wants to see how different models answer

    This triggers a multi-model comparison where the user
    can vote on which response is better.

    Args:
        message: The question to ask all models
        session_id: Session identifier

    Returns:
        Dict with model responses and battle_id for voting
    """
    from app.core.arena_manager import ArenaManager

    arena = ArenaManager()

    # Get system prompt with current context
    from app.core.arena_system_prompt import get_arena_system_prompt
    system_prompt = get_arena_system_prompt()

    # Start battle
    import asyncio
    battle_info = asyncio.run(
        arena.start_progressive_battle(
            message,
            session_id=session_id,
            system_prompt=system_prompt
        )
    )

    return {
        'arena_mode': True,
        'battle_id': battle_info['battle_id'],
        'model_a': battle_info['model_a'],
        'model_b': battle_info['model_b'],
        'response_a': battle_info['responses']['a'],
        'response_b': battle_info['responses']['b'],
        'message': 'Compare these responses and vote for the better one.'
    }


2. Agent Decision Logic:

def _should_use_arena(self, message: str) -> bool:
    """Decide if message should trigger arena comparison."""

    # Conversational patterns that benefit from Arena
    arena_patterns = [
        "what is",
        "how does",
        "why is",
        "can you explain",
        "tell me about",
        "what are the differences",
        "compare",
    ]

    message_lower = message.lower()

    # Check for conversational patterns
    is_conversational = any(pattern in message_lower for pattern in arena_patterns)

    # Check for data manipulation patterns (should NOT use arena)
    tool_patterns = [
        "show me",
        "create a",
        "run",
        "calculate",
        "analyze",
        "what are the values",
        "list the wards",
    ]

    needs_tools = any(pattern in message_lower for pattern in tool_patterns)

    # Decision: Arena if conversational AND not needing tools
    return is_conversational and not needs_tools


3. Hybrid Workflow Example:

USER: "What is the composite scoring method?"

AGENT THINKS:
- Conversational question (explanation request)
- No data manipulation needed
- Good candidate for Arena comparison
- Decision: Use Arena

AGENT RESPONDS WITH ARENA:
- Model A (Mistral): [explanation]
- Model D (GPT-4o): [explanation]
- User votes for Model D

USER: "Can you show me an example with my data?"

AGENT THINKS:
- Follow-up question
- NOW requires data access
- Decision: Use tools

AGENT RESPONDS WITH TOOL:
- Calls: create_composite_score_map(session_id)
- Shows interactive map with scores
- Explains: "Here's how composite scoring ranks your wards..."

BENEFIT: Best of both worlds!
- Arena for explanations (multiple perspectives)
- Tools for data work (visualizations, calculations)
- Agent seamlessly transitions between modes

================================================================================
PART 8: FLASK ROUTE SIMPLIFICATION
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BEFORE vs AFTER ROUTE COMPARISON                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CURRENT ROUTE (data_analysis_v3_routes.py, 680 lines):
=======================================================

@data_analysis_v3_bp.route('/api/v1/data-analysis/chat', methods=['POST'])
def data_analysis_chat():
    message = request.get_json().get('message')
    session_id = session.get('session_id')

    # Check workflow transition (10 lines)
    # Check TPR start keywords (20 lines)
    # Check TPR active (150 lines of nested ifs)
    #   - Check confirmation (30 lines)
    #   - Check stage (50 lines)
    #   - Extract keyword (40 lines)
    #   - Route to agent if no keyword (50 lines)
    # Route to pure agent (30 lines)

    # Total: ~680 lines of routing logic

PROPOSED ROUTE (simplified, ~50 lines):
========================================

@data_analysis_v3_bp.route('/api/v1/data-analysis/chat', methods=['POST'])
async def data_analysis_chat():
    """
    Unified chat endpoint - routes ALL messages through DataAnalysisAgent.

    The agent handles:
    - TPR workflow (all stages)
    - Risk analysis
    - ITN planning
    - Data queries
    - Visualizations
    - Arena comparisons
    """
    data = request.get_json()
    message = data.get('message', '')
    session_id = data.get('session_id') or session.get('session_id')

    if not session_id:
        return jsonify({'success': False, 'error': 'No session ID'}), 400

    logger.info(f"Chat message for session {session_id}: {message[:100]}")

    # Initialize unified agent
    from app.data_analysis_v3.core.agent import DataAnalysisAgent
    agent = DataAnalysisAgent(session_id)

    # Agent handles EVERYTHING
    result = await agent.analyze(message)

    # Check for workflow transitions
    if result.get('workflow_transition'):
        # Agent has determined workflow should transition
        # (e.g., TPR complete â†’ Risk analysis ready)
        return jsonify({
            'success': True,
            'exit_data_analysis_mode': True,
            'message': result['message'],
            'redirect_message': message,
            'session_id': session_id
        })

    # Return agent response
    return jsonify(result)


MAIN CHAT ROUTE (analysis_routes.py):
======================================

CURRENT (complex routing, 200+ lines):
- Check for clarification context
- Route to Mistral
- Mistral decides: Arena or Tools
- If Arena: Initialize arena, start battle, return responses
- If Tools: Initialize RequestInterpreter, process message, stream results

PROPOSED (unified agent, ~30 lines):
@analysis_bp.route('/analyze', methods=['POST'])
async def analyze():
    """Main chat endpoint - uses unified agent."""
    message = request.get_json().get('message')
    session_id = session.get('session_id')

    # Initialize unified agent
    from app.data_analysis_v3.core.agent import DataAnalysisAgent
    agent = DataAnalysisAgent(session_id)

    # Agent decides: Arena, Tools, or Hybrid
    result = await agent.analyze(message)

    return jsonify(result)


STREAMING VERSION:
==================

@analysis_bp.route('/analyze-stream', methods=['POST'])
async def analyze_stream():
    """Streaming version of unified agent."""
    message = request.get_json().get('message')
    session_id = session.get('session_id')

    from app.data_analysis_v3.core.agent import DataAnalysisAgent
    agent = DataAnalysisAgent(session_id)

    async def generate():
        async for chunk in agent.analyze_streaming(message):
            yield f"data: {json.dumps(chunk)}\n\n"

    return Response(generate(), mimetype='text/event-stream')

================================================================================
PART 9: MIGRATION ROADMAP
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP-BY-STEP IMPLEMENTATION PLAN                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: TOOL WRAPPER CREATION (Low Risk, ~2-3 days)
=====================================================

âœ… Step 1.1: Create tool wrapper files
   - app/data_analysis_v3/tools/risk_analysis_tools.py
   - app/data_analysis_v3/tools/query_tools.py
   - app/data_analysis_v3/tools/visualization_tools.py
   - app/data_analysis_v3/tools/itn_planning_tools.py
   - app/data_analysis_v3/tools/methodology_tools.py

âœ… Step 1.2: Wrap existing RequestInterpreter methods
   - Create @tool decorated functions
   - Call existing RequestInterpreter methods
   - Test each tool individually

âœ… Step 1.3: Add to agent's tool list
   - Update DataAnalysisAgent._register_all_tools()
   - Test agent can see and call tools

DELIVERABLE: Agent has access to all 11 existing tools


PHASE 2: TPR WORKFLOW CONVERSION (Medium Risk, ~3-4 days)
==========================================================

ðŸ”§ Step 2.1: Extract TPR logic to tools
   - Create app/data_analysis_v3/tools/tpr_workflow_tools.py
   - Convert handler methods to @tool functions:
     * start_tpr_workflow
     * select_tpr_state
     * select_facility_level
     * select_age_group
     * calculate_ward_tpr

ðŸ”§ Step 2.2: Update agent system prompt
   - Add TPR stage awareness to _build_phase_aware_prompt()
   - Include valid options for each stage
   - Guide agent on when to use each tool

ðŸ”§ Step 2.3: Test TPR flow with agent
   - Upload test data
   - Agent guides user through state â†’ facility â†’ age group
   - Verify agent calls correct tools
   - Compare results with old handler

ðŸ”§ Step 2.4: Remove handler routing logic
   - Keep TPRWorkflowHandler class for utility functions
   - Remove keyword detection and routing
   - Agent now handles all routing via LLM reasoning

DELIVERABLE: Agent successfully guides users through TPR workflow


PHASE 3: ARENA INTEGRATION (Medium Risk, ~2 days)
==================================================

ðŸ†• Step 3.1: Create Arena tools
   - compare_model_responses tool
   - get_arena_result tool (for follow-up questions)

ðŸ†• Step 3.2: Update agent decision logic
   - Implement _should_use_arena() method
   - Test classification accuracy (conversational vs tools)

ðŸ†• Step 3.3: Test hybrid workflows
   - Question â†’ Arena â†’ Follow-up with tool
   - Verify seamless transition

DELIVERABLE: Agent can use Arena as a capability


PHASE 4: AGENT ENHANCEMENT (Medium Risk, ~3 days)
==================================================

ðŸŽ¯ Step 4.1: Enhance system prompt building
   - Improve _build_phase_aware_prompt()
   - Add more context about available tools
   - Include recent conversation history

ðŸŽ¯ Step 4.2: Add streaming support
   - Implement analyze_streaming() method
   - Use LangGraph's streaming API
   - Test UX matches current behavior

ðŸŽ¯ Step 4.3: Session context integration
   - Load context via SessionContextService
   - Include in system prompt
   - Update on workflow transitions

DELIVERABLE: Agent provides excellent UX with streaming and context awareness


PHASE 5: ROUTE SIMPLIFICATION (Low Risk, ~1 day)
=================================================

ðŸ”„ Step 5.1: Create unified route
   - New endpoint: /api/unified/chat
   - Routes to DataAnalysisAgent
   - Test with all workflow scenarios

ðŸ”„ Step 5.2: Update frontend
   - Point React to new endpoint
   - Test all features work
   - Monitor for regressions

ðŸ”„ Step 5.3: Gradual rollout
   - Feature flag: use_unified_agent
   - A/B test with small percentage of users
   - Monitor error rates

DELIVERABLE: Simplified Flask routes using unified agent


PHASE 6: REQUESTINTERPRETER RETIREMENT (Final, ~2 days)
========================================================

ðŸ—‘ï¸ Step 6.1: Extract reusable utilities
   - Keep SessionContextService
   - Keep PromptBuilder
   - Keep ToolRunner (for tool execution logic)
   - Move to app/core/utilities/

ðŸ—‘ï¸ Step 6.2: Archive RequestInterpreter
   - Move to app/legacy/request_interpreter.py
   - Add deprecation notice
   - Keep for emergency rollback

ðŸ—‘ï¸ Step 6.3: Clean up routes
   - Remove old endpoints
   - Update documentation
   - Remove unused imports

DELIVERABLE: Clean codebase with unified agent architecture


PHASE 7: TESTING & MONITORING (Continuous, ~1 week)
====================================================

ðŸ§ª Step 7.1: Comprehensive testing
   - Unit tests for each tool
   - Integration tests for workflows
   - End-to-end tests for complete user journeys

ðŸ§ª Step 7.2: Performance monitoring
   - Agent response times
   - Tool execution latency
   - Memory usage

ðŸ§ª Step 7.3: User feedback
   - Monitor conversation quality
   - Check for tool calling accuracy
   - Collect user satisfaction metrics

DELIVERABLE: Stable, production-ready unified agent


TOTAL ESTIMATED TIME: 3-4 weeks

================================================================================
PART 10: RISKS & MITIGATION STRATEGIES
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RISK ASSESSMENT MATRIX                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RISK 1: Agent Doesn't Understand Workflow Context
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: HIGH
Probability: MEDIUM

Scenario:
- User is in TPR facility selection stage
- User says "I'm interested in rural areas"
- Agent doesn't know to select "primary" facility level

Mitigation:
- Rich system prompts with explicit stage context
- Include valid options and their meanings
- Agent can ask clarifying questions
- Fallback: If agent confused, show explicit menu

Test Plan:
- Test 100 variations of user inputs per stage
- Measure: % correctly mapped to tool calls
- Target: >95% accuracy


RISK 2: TPR Keyword Detection Breaks
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: MEDIUM
Probability: LOW

Scenario:
- Current handler has exact keyword matching
- Works because keywords are clear: "primary", "u5"
- Agent-based approach more flexible but could miss edge cases

Mitigation:
- Keep keyword hints in system prompt
- Agent learns these are preferred terms
- Agent can still understand variations
- Monitor: Track tool call success rate

Test Plan:
- Compare agent tool calls vs handler keyword matches
- Test 50 variations per keyword
- Target: Same or better accuracy


RISK 3: Tool Execution Different via LangGraph
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: MEDIUM
Probability: LOW

Scenario:
- Tool wrapper doesn't perfectly replicate original behavior
- Argument passing differs
- Session context not properly loaded

Mitigation:
- Wrapper pattern: Call EXACT same underlying methods
- Unit tests comparing wrapper vs original
- Integration tests with real sessions
- Gradual rollout with monitoring

Test Plan:
- For each tool: Run 20 test cases via wrapper and original
- Compare outputs byte-by-byte
- Target: 100% match


RISK 4: Streaming UX Changes
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: LOW
Probability: MEDIUM

Scenario:
- LangGraph streaming behaves differently
- User sees choppy responses
- Visualizations appear at wrong time

Mitigation:
- LangGraph has built-in streaming support
- Test streaming UX extensively
- Can fallback to buffering if needed
- Monitor user feedback

Test Plan:
- Side-by-side comparison: Old vs New streaming
- User testing with 10 users
- Measure: Perceived responsiveness
- Target: No degradation


RISK 5: Session State Issues Across Workers
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: HIGH
Probability: LOW

Scenario:
- Agent on Worker 1 starts TPR
- User's next message hits Worker 2
- Agent doesn't see TPR state

Mitigation:
- Already solved: File-based state flags (.tpr_complete, etc.)
- DataAnalysisStateManager handles cross-worker persistence
- Redis session storage for shared state
- No changes needed to state management

Test Plan:
- Multi-worker load test
- Force requests to different workers
- Verify state consistency
- Target: 100% state persistence


RISK 6: Performance Degradation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: MEDIUM
Probability: LOW

Scenario:
- Agent initialization overhead
- Multiple LLM calls per request
- Slower than direct tool execution

Mitigation:
- Agent already handles complex queries efficiently
- LLM call latency offset by better intent understanding
- Can cache agent instances per session
- Tool execution time unchanged (same underlying code)

Test Plan:
- Benchmark: RequestInterpreter vs Agent
- Measure: Time to first token
- Measure: Total request time
- Target: <10% slowdown acceptable


RISK 7: Arena Integration Adds Complexity
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Impact: LOW
Probability: LOW

Scenario:
- Arena tool doesn't work well
- User confusion about when Arena activates
- Arena responses not helpful in tool context

Mitigation:
- Arena activation is agent's decision (LLM chooses)
- User can always override ("just show me the data")
- Arena is optional capability (can disable)
- Keep separate Arena endpoint as fallback

Test Plan:
- Test 50 conversational queries
- Measure: Arena activation accuracy
- Measure: User satisfaction with responses
- Target: >90% appropriate activation

================================================================================
PART 11: SUCCESS METRICS
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEASURING MIGRATION SUCCESS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

METRIC 1: Code Simplicity
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Before:
- RequestInterpreter: 1743 lines
- TPRWorkflowHandler: 1543 lines
- Route logic: 680 lines
- Total: 3966 lines of routing/orchestration

After:
- DataAnalysisAgent: ~500 lines (expanded)
- Tool wrappers: ~400 lines (new)
- Route logic: ~50 lines (simplified)
- Total: ~950 lines

TARGET: 75% reduction in orchestration code


METRIC 2: Tool Calling Accuracy
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Measure: % of user intents correctly mapped to tool calls

Test Set:
- 100 TPR workflow messages (all stages)
- 50 risk analysis requests (various phrasings)
- 50 visualization requests
- 50 data query requests
- 50 ITN planning requests

TARGET: >95% correct tool selection


METRIC 3: User Experience
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Measure:
- Time to complete TPR workflow
- Number of clarification requests
- User satisfaction score (1-5)

Baseline (current):
- TPR completion: ~2-3 minutes
- Clarifications: ~1-2 per session
- Satisfaction: 4.2/5

TARGET:
- TPR completion: Same or faster
- Clarifications: Same or fewer
- Satisfaction: â‰¥4.2/5


METRIC 4: Response Quality
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Measure:
- Hallucination rate (incorrect info)
- Response relevance (1-5 scale)
- Tool result accuracy

Test: 100 diverse queries across all phases

TARGET:
- Hallucination: <2%
- Relevance: >4.5/5
- Tool accuracy: 100% (same as current)


METRIC 5: System Performance
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Measure:
- P50 response latency
- P95 response latency
- Error rate

Baseline (current):
- P50: 800ms
- P95: 3000ms
- Errors: 0.5%

TARGET:
- P50: <1000ms
- P95: <3500ms
- Errors: <1%


METRIC 6: Maintainability
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Measure:
- Time to add new tool
- Lines of code per tool
- Number of files to modify

Current:
- New tool: 3-4 hours (multiple files)
- Code per tool: 50-100 lines + registration
- Files: 3-4 (tool file, __init__, registry, interpreter)

TARGET:
- New tool: 1-2 hours (single file)
- Code per tool: 30-50 lines (just wrapper)
- Files: 2 (tool file, agent registration)

================================================================================
PART 12: IMPLEMENTATION TIMELINE
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        4-WEEK MIGRATION SCHEDULE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WEEK 1: Foundation (Tool Wrappers)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Mon-Tue: Create tool wrapper infrastructure
- Set up tool files structure
- Create first 3 wrappers (risk analysis, data query, viz)
- Test individually

Wed-Thu: Complete all 11 tool wrappers
- Wrap remaining tools
- Add to agent's tool list
- Integration testing

Fri: Testing & Documentation
- Unit tests for all wrappers
- Integration tests with agent
- Document each tool

DELIVERABLE: Agent has access to all existing tools


WEEK 2: TPR Conversion
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Mon-Tue: Extract TPR logic to tools
- Create 5 TPR workflow tools
- Test each tool individually
- Verify state transitions

Wed-Thu: Agent prompt engineering
- Update system prompts for TPR stages
- Test agent's TPR guidance
- Refine based on results

Fri: End-to-end TPR testing
- Test complete TPR workflow with agent
- Compare with handler-based flow
- Fix any issues

DELIVERABLE: Agent successfully handles TPR workflow


WEEK 3: Arena Integration & Enhancement
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Mon-Tue: Arena tool creation
- Create compare_model_responses tool
- Test Arena integration
- Verify hybrid workflows

Wed-Thu: Agent enhancements
- Add streaming support
- Improve context loading
- Optimize performance

Fri: Comprehensive testing
- Test all workflows end-to-end
- Performance benchmarking
- Bug fixes

DELIVERABLE: Fully enhanced agent with Arena


WEEK 4: Route Simplification & Deployment
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Mon-Tue: Create unified routes
- Implement simplified Flask routes
- Update frontend integration
- Feature flag setup

Wed: Gradual rollout
- Deploy to staging
- A/B test with 20% traffic
- Monitor metrics

Thu: Full rollout & cleanup
- Increase to 100% traffic
- Archive RequestInterpreter
- Clean up code

Fri: Documentation & handoff
- Update developer docs
- Write migration guide
- Team training

DELIVERABLE: Production-ready unified agent architecture

================================================================================
PART 13: ROLLBACK STRATEGY
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EMERGENCY ROLLBACK PLAN                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SCENARIO 1: Agent Tool Calling Fails
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Symptoms:
- Agent not calling tools
- Tools being called incorrectly
- High error rate

Rollback:
1. Feature flag: use_unified_agent = False
2. Route reverts to RequestInterpreter
3. Users see old behavior immediately
4. Debug agent tool calling offline

Recovery Time: <5 minutes


SCENARIO 2: TPR Workflow Issues
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Symptoms:
- TPR stages not progressing
- Selections not recorded
- State persistence broken

Rollback:
1. Restore TPRWorkflowHandler routing
2. Keep agent for other tasks
3. TPR uses old handler path

Recovery Time: <10 minutes


SCENARIO 3: Performance Degradation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Symptoms:
- Slow response times
- High latency
- Resource exhaustion

Rollback:
1. Reduce agent usage to 50%
2. Enable caching
3. If still bad, rollback to RequestInterpreter

Recovery Time: <15 minutes


SCENARIO 4: Complete System Failure
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Symptoms:
- Widespread errors
- Multiple components failing
- User-facing issues

Rollback:
1. Full rollback: use_unified_agent = False
2. Restore from Sept 30 backup if needed
3. Incident investigation

Recovery Time: <30 minutes (or restore from backup)

SAFETY NETS:
- Keep RequestInterpreter in legacy/ folder
- Maintain Sept 30 and Oct 3 backups
- Feature flags for gradual rollout
- Detailed monitoring and alerting

================================================================================
PART 14: CONCLUSION & NEXT STEPS
================================================================================

SUMMARY:
â”â”â”â”â”â”â”â”
We have a clear path to make DataAnalysisAgent the single source of truth for
ALL ChatMRPT conversations. The architecture is sound, risks are manageable,
and benefits are significant.

KEY BENEFITS:
â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Eliminate 75% of orchestration code (3966 â†’ 950 lines)
âœ… Unified conversation handling (1 agent vs 3 systems)
âœ… Easier to add capabilities (just add tools)
âœ… Consistent UX across all workflow phases
âœ… Agent learns from conversation history
âœ… Arena integrated as capability, not separate system
âœ… Tools available throughout (no more hard boundaries)

IMMEDIATE NEXT STEPS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Review this document with team
2. Get alignment on approach
3. Create detailed task breakdown
4. Set up development branch
5. Begin Week 1: Tool wrapper creation

OPEN QUESTIONS FOR DISCUSSION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Should we start with parallel system (new /api/v2 route)?
2. What percentage for initial A/B test? (Recommend: 10-20%)
3. Which workflows to test first? (Recommend: TPR, then Risk)
4. Timeline acceptable? Can we commit 4 weeks?
5. Who will be primary developer on this migration?

RECOMMENDATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PROCEED with migration. The architecture is well-designed, risks are mitigated,
and the long-term benefits justify the 4-week investment. Start with tool
wrappers (low risk) and build confidence before TPR conversion.

================================================================================
END OF DOCUMENT
================================================================================

This document represents comprehensive architectural analysis and planning for
migrating ChatMRPT to a unified agent-based system. It should be reviewed by
another agent or developer for validation and refinement before implementation.

Generated: October 3, 2025
Author: Claude (Data Analysis Agent Architecture Team)
Status: READY FOR REVIEW
