# TPR LLM-First Implementation - COMPREHENSIVE FIX PLAN

**Date**: 2025-10-10
**Status**: Pre-Deployment Fixes Required
**Target**: Fix all critical and high-impact issues before deployment

---

## Issues Summary (From Realistic Testing)

| Issue | Impact | Pass Rate | Priority | Status |
|-------|--------|-----------|----------|--------|
| #1: Negation Misclassification | HIGH | 20% | CRITICAL | Not Fixed |
| #2: Very Short Inputs | MEDIUM | 50% | HIGH | Not Fixed |
| #3: Agent Data Context | CRITICAL | 0/12 columns | CRITICAL | Not Fixed |
| #4: data_inquiry vs info_request | LOW | 14.3% | MEDIUM | Not Fixed |
| #5: Multiple Intent Handling | LOW | 25% | LOW | Not Fixed |
| #6: Flask Import (Test Only) | TEST | N/A | LOW | Not Fixed |

---

## FIX #1: Negation Detection (CRITICAL)

### Problem
Users saying "not primary", "don't want secondary" get classified as **selection** instead of **navigation/rejection**.

**Impact**: HIGH - System does the OPPOSITE of what user wants!

**Examples**:
- "not primary" â†’ classified as selection, extracted "secondary" âŒ
- "i don't want secondary" â†’ classified as selection, extracted "primary" âŒ
- "no not that one" â†’ classified as selection âŒ

### Root Cause
LLM tries to be helpful by inferring alternatives:
- "not primary" â†’ LLM thinks "oh, they must want secondary/tertiary"
- This is WRONG - user is rejecting, not selecting

### Solution

**File**: `app/data_analysis_v3/core/tpr_language_interface.py`

**Implementation**:

```python
def classify_intent(self, message: str, stage: str, context: Optional[Dict[str, Any]] = None) -> IntentResult:
    """Classify user intent within the TPR workflow using LLM-first approach."""

    # ULTRA-FIX #1: Detect negations FIRST
    message_lower = message.lower().strip()

    # Negation patterns
    negation_patterns = [
        'not ', 'don\'t', 'dont', 'do not', 'doesn\'t', 'doesnt',
        'no ', 'nah ', 'nope', 'never', 'none', 'neither'
    ]

    # Check if message contains negation
    has_negation = any(pattern in message_lower for pattern in negation_patterns)

    # If negation detected AND contains selection keywords, classify as navigation
    if has_negation:
        selection_keywords = ['primary', 'secondary', 'tertiary', 'u5', 'o5', 'pw', 'under', 'over', 'pregnant']
        has_selection_keyword = any(keyword in message_lower for keyword in selection_keywords)

        if has_selection_keyword:
            logger.info(f"ðŸš« Negation detected: '{message}' â†’ navigation (rejection)")
            return IntentResult(
                intent='navigation',
                confidence=0.95,
                rationale='User is rejecting a selection (negation detected)',
                extracted_value=None
            )

    # Continue with normal flow (fast-path, then LLM)...
```

**Test Cases After Fix**:
- "not primary" â†’ navigation âœ“
- "don't want secondary" â†’ navigation âœ“
- "no not that one" â†’ navigation âœ“
- "anything except tertiary" â†’ navigation âœ“

---

## FIX #2: Very Short Input Handling (HIGH PRIORITY)

### Problem
Single character or very short inputs are impossible to classify accurately.

**Impact**: MEDIUM - Users get confused responses

**Examples**:
- "?" â†’ classified as information_request (expected: general)
- "k" â†’ classified as general (expected: confirmation)
- "no" â†’ classified as confirmation (expected: navigation)

### Root Cause
LLM has insufficient context to determine intent from 1-2 characters.

### Solution

**File**: `app/data_analysis_v3/core/tpr_language_interface.py`

**Implementation**:

```python
def classify_intent(self, message: str, stage: str, context: Optional[Dict[str, Any]] = None) -> IntentResult:
    """Classify user intent within the TPR workflow using LLM-first approach."""

    # ... negation check ...

    # ULTRA-FIX #2: Handle very short inputs with enhanced mapping
    if len(message.strip()) <= 2:
        logger.info(f"âš¡ Very short input detected: '{message}' (length={len(message.strip())})")

        # Enhanced short input mapping
        short_input_map = {
            # Confirmations
            'ok': ('confirmation', 0.9),
            'k': ('confirmation', 0.8),
            'y': ('confirmation', 0.7),
            'yes': ('confirmation', 0.95),
            'ya': ('confirmation', 0.85),
            'ye': ('confirmation', 0.85),

            # Negations
            'no': ('navigation', 0.9),
            'n': ('navigation', 0.7),

            # Questions
            '?': ('information_request', 0.6),

            # General
            '??': ('general', 0.5),
            '...': ('general', 0.5),
        }

        normalized = message.lower().strip()
        if normalized in short_input_map:
            intent, confidence = short_input_map[normalized]
            logger.info(f"   Mapped to: {intent} (confidence={confidence})")
            return IntentResult(
                intent=intent,
                confidence=confidence,
                rationale=f'Short input mapped: "{message}" â†’ {intent}'
            )
        else:
            # Fall back to baseline for unknown short inputs
            return self._baseline_intent(message, stage, context)

    # Continue with normal flow...
```

**Test Cases After Fix**:
- "ok", "k" â†’ confirmation âœ“
- "yes", "y" â†’ confirmation âœ“
- "no", "n" â†’ navigation âœ“
- "?" â†’ information_request âœ“

---

## FIX #3: Agent Data Context (CRITICAL!)

### Problem
**MOST IMPORTANT ISSUE**: Agent receives data context but doesn't mention actual column names when asked.

**Impact**: CRITICAL - Core user deviation scenario doesn't work!

**Test Result**:
```
Query: "what variables do I have?"
â†’ success: True
â†’ columns mentioned: 0/12  âŒ AGENT NOT USING DATA CONTEXT
```

### Root Cause Analysis

Need to check:
1. Is workflow_context actually passed to agent?
2. Does agent extract data_columns from workflow_context?
3. Does agent prompt include data_columns?
4. Is agent actually using this in its response?

### Solution - Multi-Part Fix

#### Part 3A: Verify Workflow Context is Passed

**File**: `app/data_analysis_v3/core/tpr_workflow_handler.py`

Check `_handoff_to_agent()` method (lines 852-905):

```python
def _handoff_to_agent(...):
    """Hand off to agent with rich context about workflow state and data."""

    workflow_context = {
        'in_tpr_workflow': True,
        'stage': stage,
        'valid_options': valid_options,
        'current_selections': self.tpr_selections,
        'context_type': context_type,

        # CRITICAL: Ensure data context is included
        'data_loaded': self.uploaded_data is not None,
        'data_columns': list(self.uploaded_data.columns) if self.uploaded_data is not None else [],
        'data_shape': {
            'rows': self.uploaded_data.shape[0] if self.uploaded_data is not None else 0,
            'cols': self.uploaded_data.shape[1] if self.uploaded_data is not None else 0
        },

        # Add column details for better context
        'column_names': ', '.join(list(self.uploaded_data.columns)[:10]) if self.uploaded_data is not None else 'No data',

        'workflow_reminder': f"After helping the user, gently remind them..."
    }

    logger.info(f"ðŸ”„ Handing off to agent with context:")
    logger.info(f"   - Data columns: {len(workflow_context.get('data_columns', []))} columns")
    logger.info(f"   - First 5 columns: {workflow_context.get('data_columns', [])[:5]}")
```

#### Part 3B: Enhance Agent to Use Data Context

**File**: `app/data_analysis_v3/core/agent.py`

Update the context message creation in `analyze()`:

```python
async def analyze(self, user_query: str, workflow_context: Dict[str, Any] = None) -> Dict[str, Any]:
    """Main entry point for data analysis."""

    # ... existing code ...

    # Add workflow context to system prompt if provided
    context_message = None
    if workflow_context:
        stage = workflow_context.get('stage', 'unknown')
        options = workflow_context.get('valid_options', [])
        data_columns = workflow_context.get('data_columns', [])
        column_names = workflow_context.get('column_names', '')

        # ULTRA-FIX #3: Make data context EXPLICIT in message
        context_parts = [
            f"[WORKFLOW CONTEXT]",
            f"User is in TPR workflow at '{stage}' stage.",
            f"Valid options: {', '.join(options)}.",
        ]

        # Add explicit data context
        if data_columns:
            context_parts.append(f"\n**IMPORTANT: User's dataset has {len(data_columns)} columns:**")
            context_parts.append(f"Columns: {', '.join(data_columns[:15])}")
            if len(data_columns) > 15:
                context_parts.append(f"...and {len(data_columns) - 15} more columns")
            context_parts.append(f"\n**When user asks about variables/columns, LIST THESE SPECIFIC COLUMNS.**")

        context_parts.append(f"\nIf they ask questions, answer them fully and then gently remind them where they are in the workflow.")

        context_message = HumanMessage(content='\n'.join(context_parts))
```

#### Part 3C: Update System Prompt to Use Data Context

**File**: `app/data_analysis_v3/prompts/system_prompt.py`

Update MAIN_SYSTEM_PROMPT:

```python
MAIN_SYSTEM_PROMPT = """You are a specialized data analysis assistant...

IMPORTANT INSTRUCTIONS:
1. When user asks "what variables/columns do I have?", CHECK THE CONTEXT for actual column names
2. LIST the specific columns from the dataset, don't give generic answers
3. Use the data_columns provided in the context messages
4. Be specific and concrete, not vague

..."""
```

#### Part 3D: Test Fix

Create test to verify:

```python
# Test that agent actually mentions columns
result = agent.analyze(
    "what variables do I have?",
    workflow_context={
        'data_columns': ['State', 'LGA', 'Ward', 'TPR', 'Tests'],
        'column_names': 'State, LGA, Ward, TPR, Tests',
        'data_shape': {'rows': 100, 'cols': 5}
    }
)

assert 'State' in result['message']  # Should mention specific columns!
assert 'LGA' in result['message']
assert 'Ward' in result['message']
```

---

## FIX #4: data_inquiry vs information_request Boundaries (MEDIUM)

### Problem
LLM confuses asking ABOUT data with asking FOR information.

**Impact**: LOW - Both route to agent, so user gets answer

**Examples**:
- "show me variables" â†’ information_request (expected: data_inquiry)
- "what columns do I have" â†’ information_request (expected: data_inquiry)

### Solution

**File**: `app/data_analysis_v3/core/tpr_language_interface.py`

Update LLM prompt with clearer examples:

```python
# In classify_intent() prompt
"""
2. **information_request** - User asking about OPTIONS/EXPLANATIONS/CHOICES
   Examples: "explain the differences", "what are the options?", "what does primary mean?"
   Keywords: explain, differences, options, mean, tell me about [the options]

3. **data_inquiry** - User asking about THEIR UPLOADED DATA/VARIABLES/COLUMNS
   Examples: "what variables do I have?", "show me my data columns", "what's in my dataset?"
   Keywords: variables, columns, my data, dataset, what do I have, show me [my data]

Key Distinction:
- "what are my options?" â†’ information_request (asking about workflow choices)
- "what columns do I have?" â†’ data_inquiry (asking about their data)
- "show me the options" â†’ information_request (asking about workflow)
- "show me my variables" â†’ data_inquiry (asking about their dataset)
"""
```

**Alternative**: Merge these intents into one since both route to agent.

---

## FIX #5: Multiple Intent Prioritization (LOW PRIORITY)

### Problem
When user asks multiple things, LLM picks one (often the last).

**Impact**: LOW - User can ask again

**Examples**:
- "show me columns and then plot TPR" â†’ analysis_request (wanted: data_inquiry)
- "what are my options? i want primary" â†’ information_request (wanted: selection)

### Solution

**File**: `app/data_analysis_v3/core/tpr_language_interface.py`

Add prioritization logic:

```python
def classify_intent(self, message: str, stage: str, context: Optional[Dict[str, Any]] = None) -> IntentResult:
    """Classify user intent within the TPR workflow using LLM-first approach."""

    # ... negation check ...
    # ... short input check ...
    # ... fast-path check ...

    # ULTRA-FIX #5: Prioritize selections over other intents
    # Check if message contains selection keyword + action verb
    selection_indicators = [
        'i want', 'i choose', 'i select', 'i pick', 'i\'ll take',
        'let\'s go', 'choose', 'select', 'pick', 'take'
    ]

    has_selection_indicator = any(indicator in message.lower() for indicator in selection_indicators)

    if has_selection_indicator:
        # Call LLM but hint to prioritize selection
        context = context or {}
        context['prioritize_selection'] = True

    # Continue with LLM call...
    # In prompt, add: "If message contains BOTH a selection and a question, classify as 'selection'"
```

---

## FIX #6: Flask Import for Testing (LOW PRIORITY)

### Problem
Workflow handler has Flask dependency that breaks outside Flask context.

**Impact**: TEST ONLY - Works fine in production

### Solution

**File**: `app/data_analysis_v3/core/tpr_workflow_handler.py`

Make Flask imports conditional:

```python
# At top of file
try:
    from flask import current_app
    HAS_FLASK = True
except ImportError:
    HAS_FLASK = False
    current_app = None

# In code where Flask is used
if HAS_FLASK and current_app:
    # Use Flask features
    pass
else:
    # Fallback for testing
    pass
```

---

## Implementation Order (Priority)

1. **FIX #3: Agent Data Context** (CRITICAL) - 2 hours
   - Must work for core user deviation scenario
   - Verify agent mentions actual columns
   - Test end-to-end

2. **FIX #1: Negation Detection** (CRITICAL) - 30 minutes
   - Quick fix, high impact
   - Add before LLM call
   - Test thoroughly

3. **FIX #2: Very Short Inputs** (HIGH) - 30 minutes
   - Add mapping for common short responses
   - Improves UX significantly

4. **FIX #4: Intent Boundaries** (MEDIUM) - 1 hour
   - Update LLM prompt
   - Test classification accuracy

5. **FIX #5: Multiple Intents** (LOW) - 30 minutes
   - Add prioritization logic
   - Nice-to-have improvement

6. **FIX #6: Flask Import** (LOW) - 15 minutes
   - Test-only issue
   - Quick conditional import

**Total Estimated Time**: 4-5 hours

---

## Testing Plan After Fixes

### Test Suite 1: Regression Tests
- Re-run all 113 realistic user tests
- Target: >85% pass rate (vs current 71.7%)

### Test Suite 2: Agent Data Context Tests
- "what variables do I have?" â†’ Should list specific columns
- "how many columns?" â†’ Should give exact count
- "describe my dataset" â†’ Should mention actual columns
- **Critical**: Verify agent USES the data context!

### Test Suite 3: Negation Tests
- "not primary" â†’ navigation âœ“
- "don't want secondary" â†’ navigation âœ“
- "anything except tertiary" â†’ navigation âœ“
- "no not that one" â†’ navigation âœ“

### Test Suite 4: Short Input Tests
- "ok", "k" â†’ confirmation âœ“
- "no", "n" â†’ navigation âœ“
- "?" â†’ information_request âœ“

### Test Suite 5: End-to-End Workflow
1. Upload real data
2. Start TPR workflow
3. Ask "what variables do I have?" â†’ Agent lists columns
4. Select "primary"
5. Ask "show missing values" â†’ Agent analyzes
6. Select "u5"
7. Verify workflow completes

**Success Criteria**: All tests pass, agent handoff works end-to-end

---

## Success Metrics

**Before Fixes**:
- Realistic tests: 71.7% (81/113)
- Negations: 20% (1/5)
- Short inputs: 50% (5/10)
- Agent data context: 0/12 columns mentioned

**Target After Fixes**:
- Realistic tests: >85% (>96/113)
- Negations: >80% (>4/5)
- Short inputs: >80% (>8/10)
- Agent data context: 100% (mentions all relevant columns)

---

## Risk Assessment

**Low Risk Fixes**:
- Negation detection (pre-LLM check)
- Short input mapping (pre-LLM check)
- Flask import (conditional)

**Medium Risk Fixes**:
- Agent data context (changes prompts)
- Intent boundary clarification (LLM prompt changes)

**Mitigation**:
- Test each fix independently
- Keep backups of original files
- Incremental deployment
- Monitor logs closely

---

## Deployment Checklist (After Fixes)

- [ ] All 6 fixes implemented
- [ ] Regression tests pass (>85%)
- [ ] Agent data context verified (mentions columns)
- [ ] Negation tests pass (>80%)
- [ ] Short input tests pass (>80%)
- [ ] End-to-end workflow tested
- [ ] Code reviewed
- [ ] Documentation updated
- [ ] Ready for production deployment

---

## Next Steps

1. Implement fixes in order of priority
2. Test each fix individually
3. Run full regression suite
4. Verify agent handoff works end-to-end
5. Deploy to production with monitoring
