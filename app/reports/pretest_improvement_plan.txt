ChatMRPT Pretest Improvement Plan (Timeline)
====================================================

Objective
---------
Resolve the critical UX and reliability issues surfaced during MVP1 pretest—session resets, missing multi-level visualizations, unreliable data answers, rigid analysis flows, and dual TPR workflows—within the current two-week window.

Guiding Principles
------------------
1. Preserve data privacy while keeping user context intact.
2. Present a single, trustworthy view of uploaded data to every agent/tool.
3. Make visual outputs and workflows flexible so users can iterate without starting over.
4. Give users a clear choice between recalculating TPR or importing vetted DHIS2 rates.

Workstreams
-----------
1. **Session & Conversation Continuity**
   - Introduce a stable `conversation_id` stored in both backend and frontend so user chats persist even if a new upload session ID is minted.
   - On upload, migrate conversation history, memory summaries, and breadcrumbs from the previous ID to the new one, then rebind the frontend store without wiping messages.
   - Extend regression tests to cover “upload after chatting” and “clear chat” scenarios to ensure data is not lost.

2. **Unified Data Access Layer**
   - Elevate `UnifiedDataState` to the default entry point for all agents/tools (Request Interpreter, LangGraph, visualization services, ITN planner).
   - Sync Flask session flags (`csv_loaded`, `analysis_complete`) from `.analysis_complete` marker + unified dataset presence at the start of each request to avoid stale routing decisions.
   - Remove redundant pipelines (e.g., `FlexibleDataAccess` reruns) and document the new data-service contract so future features plug into a single source of truth.

3. **Visualization Level Toggling**
   - Aggregate metrics at state/LGA/ward levels for every map we ship; cache those aggregates to keep toggling responsive.
   - Embed Plotly `updatemenus` in saved HTML so users can switch levels inline; reflect the selection state in legends/tooltips.
   - Update `VisualizationFrame` controls (and optional drill-down breadcrumbs) so the UI clearly shows the current level and gracefully adapts to fewer polygons when zoomed out.

4. **Workflow Flexibility & Reruns**
   - Capture analysis runs (variable set, thresholds, timestamps) and persist them per session so users can revisit or clone a run.
   - Provide a chat command/UI action (“rerun with …”) that reuses the existing dataset while allowing parameter tweaks without re-uploading.
   - Store outputs for each run (tables, maps) with version tags so the UI can show multiple iterations side by side.

5. **TPR Workflow Options**
   - Detect DHIS2-style pre-calculated TPR uploads and prompt users to choose between recalculation (raw NMEP path) or using existing TPR values.
   - For the pre-calculated path, validate schema/granularity, fix ward-name mismatches, and feed the data directly into the main analysis flow while tagging provenance.
   - For the recalculation path, keep the interactive TPR module but ensure its outputs pass through the same standard interface so downstream tools don’t need special cases.

Timeline
--------------------
- **Days 1–2 (completed):** Architecture & planning workshops covering session continuity, unified data service, TPR options, and workflow iterations.
- **Day 3–4:** Implement multi-level visualization toggling (backend aggregations + React controls). Deliver ward/LGA/state switching for core maps first, then variable distributions.
- **Day 5:** Stand up conversation continuity changes (stable `conversation_id`, chat migration on upload) and begin `UnifiedDataState` refactor for critical consumers.
- **Day 6:** Finish TPR dual-path implementation (upload detection, user choice prompt, schema validation).
- **Week 2:**
  - *Day 7–8:* Complete unified data access refactor and regression tests.
  - *Day 8–9:* Implement rerun foundation (analysis run metadata + basic “rerun with new variables” command) and persist multi-run outputs.
  - *Day 10–11:* Polish rerun UX, finalize documentation, and run targeted user validations.
  - *Day 12:* Hardening, stakeholder demo, and pretest rehearsal.

